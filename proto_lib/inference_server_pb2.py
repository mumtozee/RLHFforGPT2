# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: inference_server.proto
# Protobuf Python Version: 4.25.0
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x16inference_server.proto\x12\x0cgpt2_service\"\xa6\x01\n\rPromptRequest\x12\x0e\n\x06prompt\x18\x01 \x01(\t\x12L\n\x11generation_params\x18\x02 \x03(\x0b\x32\x31.gpt2_service.PromptRequest.GenerationParamsEntry\x1a\x37\n\x15GenerationParamsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\"\xb0\x01\n\x0ePromptResponse\x12\x16\n\x0egenerated_text\x18\x01 \x01(\t\x12M\n\x11usage_information\x18\x02 \x03(\x0b\x32\x32.gpt2_service.PromptResponse.UsageInformationEntry\x1a\x37\n\x15UsageInformationEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\x05:\x02\x38\x01\x32V\n\x0bGPT2Service\x12G\n\x08Generate\x12\x1b.gpt2_service.PromptRequest\x1a\x1c.gpt2_service.PromptResponse\"\x00\x62\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'inference_server_pb2', _globals)
if _descriptor._USE_C_DESCRIPTORS == False:
  DESCRIPTOR._options = None
  _globals['_PROMPTREQUEST_GENERATIONPARAMSENTRY']._options = None
  _globals['_PROMPTREQUEST_GENERATIONPARAMSENTRY']._serialized_options = b'8\001'
  _globals['_PROMPTRESPONSE_USAGEINFORMATIONENTRY']._options = None
  _globals['_PROMPTRESPONSE_USAGEINFORMATIONENTRY']._serialized_options = b'8\001'
  _globals['_PROMPTREQUEST']._serialized_start=41
  _globals['_PROMPTREQUEST']._serialized_end=207
  _globals['_PROMPTREQUEST_GENERATIONPARAMSENTRY']._serialized_start=152
  _globals['_PROMPTREQUEST_GENERATIONPARAMSENTRY']._serialized_end=207
  _globals['_PROMPTRESPONSE']._serialized_start=210
  _globals['_PROMPTRESPONSE']._serialized_end=386
  _globals['_PROMPTRESPONSE_USAGEINFORMATIONENTRY']._serialized_start=331
  _globals['_PROMPTRESPONSE_USAGEINFORMATIONENTRY']._serialized_end=386
  _globals['_GPT2SERVICE']._serialized_start=388
  _globals['_GPT2SERVICE']._serialized_end=474
# @@protoc_insertion_point(module_scope)
